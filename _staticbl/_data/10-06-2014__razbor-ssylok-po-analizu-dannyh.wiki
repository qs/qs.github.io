title: Разбор ссылок по анализу данных
tags: data-mining 
date: 10-06-2014 01:47

Разбор ссылок с http://habrahabr.ru/post/225589/

[[http://nosql-database.org/|Список NoSQL баз данных]] - полезный список, помимо баз есть еще события (конфы).
Хорошие базы, которые надо иметь ввиду: 
* семейства столбцов: HBase - для хадупа, Cassandra - аналог hbase; 
* док.ориентированные: MongoDB - круто развит, Elasticsearch - для текстовых документов/логов; 
* ключ-значение: DynamoDB - "automatic ultra scalable", Riak - в отличии от Redis есть Multiple Masters, LevelDB - используется в биткоинах, баз ключ-значение дофига. 
* графовые: Neo4J - куча всего, Infinite Graph - тоже.
* Multimodel Databases - крутые, нужно подробнее разобраться с некоторыми: ArangoDB, AlchemyDB

[[http://simplystatistics.org/2014/05/22/10-things-statistics-taught-us-about-big-data-analysis/|10 вещей из статистики применимые при анализе больших данных]]
# Если целью является точность, нужно составлять результат из нескольких моделей.
# Нужно тестировать много гипотез на множестве тестов.
# Есть данные пространственные и временные, нужно из сгладить: [[http://www.people.fas.harvard.edu/~gov2000/Handouts/lowess.pdf|loess]], [[http://ru.wikipedia.org/wiki/%D0%A1%D0%B3%D0%BB%D0%B0%D0%B6%D0%B8%D0%B2%D0%B0%D1%8E%D1%89%D0%B8%D0%B9_%D1%81%D0%BF%D0%BB%D0%B0%D0%B9%D0%BD|Сглаживающий сплайн]], [[http://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%BE%D0%BB%D1%8C%D0%B7%D1%8F%D1%89%D0%B0%D1%8F_%D1%81%D1%80%D0%B5%D0%B4%D0%BD%D1%8F%D1%8F|Скользящая средняя]], [[http://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D1%80%D1%8B%D1%82%D0%B0%D1%8F_%D0%BC%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C|Скрытая марковская модель]]
# Перед тем, как анализировать данные, попробовать их отобразить [[http://ru.wikipedia.org/wiki/%D0%9A%D0%B2%D0%B0%D1%80%D1%82%D0%B5%D1%82_%D0%AD%D0%BD%D1%81%D0%BA%D0%BE%D0%BC%D0%B1%D0%B0|Квартет Энскомба]], [[http://en.wikipedia.org/wiki/Bland%E2%80%93Altman_plot|Bland–Altman plot]]
# ИНтерактивный анализ - лучший способ выяснить, что на самом деле происходит с данными. (Robert Gentleman, Genentech: "make big data as small as possible as quick as is possible")
# Нужно знать реальный размер выборки.
# Unless you ran a randomized trial, potential confounders should keep you up at night
# Определить метрику успеха
# Нужно писать код и оформлять данные так, чтобы более опытные аналитики могли проверить результаты
# Нужно использовар разные инструменты, а не только тот, который знаешь лучше.

[[https://medium.com/data-science-analytics/building-data-science-teams-f06352dcada8|Building Data Science Teams]]
Нужны:
* Data evangelist
* Contextual analyst
* Data visualizer

